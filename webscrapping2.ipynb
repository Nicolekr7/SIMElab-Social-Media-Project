{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64636e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Excel successfully!\n"
     ]
    }
   ],
   "source": [
    "#Mpasho\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://mpasho.co.ke/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Scraping data and storing it in a DataFrame\n",
    "# Here you need to modify according to the specific data you want to scrape\n",
    "# For demonstration purposes, let's say we want to scrape all the links on the page\n",
    "links = [link.get('href') for link in soup.find_all('a')]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Links': links})\n",
    "\n",
    "# Specify the file path\n",
    "file_path = r\"C:\\Users\\Admin\\Desktop\\SIMElab_Data\\mpasho_links.xlsx\"\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "df.to_excel(file_path, index=False)\n",
    "\n",
    "print(\"Data saved to Excel successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6062c91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Excel successfully!\n"
     ]
    }
   ],
   "source": [
    "#Bnn\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://bnn.ke/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Scraping data and storing it in a DataFrame\n",
    "# Modify this part according to the specific data you want to scrape\n",
    "# For demonstration purposes, let's say we want to scrape all the headlines\n",
    "headlines = [headline.text for headline in soup.find_all('h2')]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Headlines': headlines})\n",
    "\n",
    "# Specify the file path\n",
    "file_path = r\"C:\\Users\\Admin\\Desktop\\SIMElab_Data\\bnn_headlines.xlsx\"\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "df.to_excel(file_path, index=False)\n",
    "\n",
    "print(\"Data saved to Excel successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d5d6e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped Article Titles:\n",
      "\n",
      "Data saved to Excel successfully at:\n",
      "C:\\Users\\Admin\\tuko_articles.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Tuko\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.tuko.co.ke/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Scraping data and storing it in a list\n",
    "# Modify this part according to the specific data you want to scrape\n",
    "# For demonstration purposes, let's say we want to scrape all the article titles\n",
    "article_titles = [title.text.strip() for title in soup.find_all('h2', class_='article-title')]\n",
    "\n",
    "# Print the scraped data\n",
    "print(\"Scraped Article Titles:\")\n",
    "for title in article_titles:\n",
    "    print(title)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Article Titles': article_titles})\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"tuko_articles.xlsx\"  # Save in the current directory\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "df.to_excel(file_path, index=False)\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "print(\"\\nData saved to Excel successfully at:\")\n",
    "print(os.path.join(cwd, file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e08e3f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article titles extracted successfully.\n",
      "\n",
      "Extracted Article Titles:\n",
      "\n",
      "DataFrame created successfully.\n",
      "Error occurred while saving DataFrame to Excel: Cannot save file into a non-existent directory: 'path\\to\\your'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.tuko.co.ke/latest/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Scraping data and storing it in a list\n",
    "# Modify this part according to the specific data you want to scrape\n",
    "# For demonstration purposes, let's say we want to scrape all the article titles\n",
    "\n",
    "article_titles = []\n",
    "try:\n",
    "    article_titles = [title.text.strip() for title in soup.find_all('h2', class_='article-title')]\n",
    "    print(\"Article titles extracted successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while extracting article titles:\", e)\n",
    "\n",
    "# Print the extracted titles\n",
    "print(\"\\nExtracted Article Titles:\")\n",
    "for title in article_titles:\n",
    "    print(title)\n",
    "\n",
    "# Create a DataFrame\n",
    "try:\n",
    "    df = pd.DataFrame({'Article Titles': article_titles})\n",
    "    print(\"\\nDataFrame created successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while creating DataFrame:\", e)\n",
    "\n",
    "# Specify the file path\n",
    "file_path = r\"C:\\Users\\Admin\\Desktop\\SIMElab_Data\\tuko_articles.xlsx\"\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "\n",
    "import os\n",
    "\n",
    "file_path = \"path/to/your/file.xlsx\"\n",
    "\n",
    "try:\n",
    "    df.to_excel(file_path, index=False)\n",
    "    print(\"\\nData saved to Excel successfully at:\", file_path)\n",
    "except Exception as e:\n",
    "        print(\"Error occurred while saving DataFrame to Excel:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a94d7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Excel successfully!\n"
     ]
    }
   ],
   "source": [
    "#KENYANS.CO.KE\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.kenyans.co.ke/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Scraping data and storing it in a DataFrame\n",
    "# Here you need to modify according to the specific data you want to scrape\n",
    "# For demonstration purposes, let's say we want to scrape all the links on the page\n",
    "links = [link.get('href') for link in soup.find_all('a')]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Links': links})\n",
    "\n",
    "# Specify the file path\n",
    "file_path = r\"C:\\Users\\Admin\\Desktop\\SIMElab_Data\\kenyans.co.ke.xlsx\"\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "df.to_excel(file_path, index=False)\n",
    "\n",
    "print(\"Data saved to Excel successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c63bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
